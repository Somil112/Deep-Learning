{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGeneration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vEt7nhPfECRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a7c56b18-704c-478a-ad53-fb5b1b1446d3"
      },
      "cell_type": "code",
      "source": [
        "!pip install music21"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting music21\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/db/317c21f4b5b970c3bfb5ff321e333059faf775621ae6433abcd4c68c69db/music21-5.3.0.tar.gz (18.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 18.0MB 2.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: music21\n",
            "  Running setup.py bdist_wheel for music21 ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/53/8b/a6/be1921c60a68f0bea31c6b6a0a7b125badd61294d6a694407f\n",
            "Successfully built music21\n",
            "Installing collected packages: music21\n",
            "Successfully installed music21-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vPEySOzdFn8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing files from google drive"
      ]
    },
    {
      "metadata": {
        "id": "oQyfqcfuEluk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7ad2566b-94ea-454a-d03e-2d8b09146cb3"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f2YgUm10GI97",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing the required libraries"
      ]
    },
    {
      "metadata": {
        "id": "u-0tKbiyGNGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "from music21 import converter, instrument, note, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4VfsUvTKGh3z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function for training the network\n"
      ]
    },
    {
      "metadata": {
        "id": "ZlsVYIw_G4-z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_network():\n",
        "  #Getting the notes of the music\n",
        "  \n",
        "  notes = get_notes()\n",
        "  \n",
        "  #defining the length of our vocabulary\n",
        "  \n",
        "  n_vocab = len(set(notes))\n",
        "  \n",
        "  #preparing sequences\n",
        "  \n",
        "  network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "  \n",
        "  #Creating the model\n",
        "  \n",
        "  model=create_network(network_input, n_vocab)\n",
        "  \n",
        "  #training the model\n",
        "  \n",
        "  train(model, network_input, network_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUNkn9fpI1fK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting the notes from midi files"
      ]
    },
    {
      "metadata": {
        "id": "WvrVf9PSJBda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_notes():\n",
        "  \n",
        "  notes = []\n",
        "  \n",
        "  for file in glob.glob(\"drive/My Drive/RapMusic/*.mid\"):\n",
        "    \n",
        "    midi = converter.parse(file)\n",
        "    \n",
        "    print(\"Parsing %s\" %file)\n",
        "    \n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    \n",
        "    notes_to_parse = None\n",
        "    \n",
        "    # file has instrument parts\n",
        "    \n",
        "    if parts: \n",
        "      \n",
        "      notes_to_parse = parts.parts[0].recurse\n",
        "    \n",
        "    else: \n",
        "    # file has notes in a flat structure\n",
        "      \n",
        "      notes_to_parse = midi.flat.notes\n",
        "\n",
        "  for element in notes_to_parse:\n",
        "    \n",
        "    if isinstance(element, note.Note):\n",
        "      \n",
        "      notes.append(str(element.pitch))\n",
        "      \n",
        "    elif isinstance(element, chord.Chord):\n",
        "      \n",
        "      notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "            \n",
        "\n",
        "            \n",
        "  return notes\n",
        "\n",
        "\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnrYEOLwLYPK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparing sequences for your model"
      ]
    },
    {
      "metadata": {
        "id": "_ejdVSwZLg95",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "  \n",
        "  sequence_length = 100\n",
        "  \n",
        "  pitchnames=sorted(set(item for item in notes))\n",
        "  \n",
        "  note_to_int=dict((note,number) for number,note in enumerate(pitchnames))\n",
        "  \n",
        "  network_input = []\n",
        "  \n",
        "  network_output = []\n",
        "  \n",
        "  for i in range(0,len(notes)-sequence_length,1):\n",
        "    \n",
        "    sequence_in = notes[i:i+sequence_length]\n",
        "    \n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    \n",
        "    network_input.append([note_to_int[char] for char in sequence_in])\n",
        "    \n",
        "    network_output.append(note_to_int[sequence_out])\n",
        "    \n",
        "  n_patterns=len(network_input)\n",
        "  \n",
        "  network_input = np.reshape(network_input, (n_patterns,sequence_length,1))\n",
        "  \n",
        "  network_input = network_input/float(n_vocab)\n",
        "  \n",
        "  network_output=np_utils.to_categorical(network_output)\n",
        "    \n",
        "  return (network_input, network_output)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3HmBDAhrez6L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating the model"
      ]
    },
    {
      "metadata": {
        "id": "FrcjrTK9fBwM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "  \n",
        "  model=Sequential()\n",
        "  \n",
        "  model.add(LSTM(512,input_shape=(network_input.shape[1],network_input.shape[2]),return_sequences=True))\n",
        "  \n",
        "  model.add(Dropout(0.4))\n",
        "  \n",
        "  model.add(LSTM(512,return_sequences=True))\n",
        "  \n",
        "  model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(LSTM(512))\n",
        "  \n",
        "  model.add(Dense(256))\n",
        "  \n",
        "  model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(Dense(n_vocab))\n",
        "  \n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQYr1LG-iopX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training your model"
      ]
    },
    {
      "metadata": {
        "id": "TceDhwB1ivWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3243
        },
        "outputId": "946f5ff2-7460-47f3-86cc-a3cec2ecdeec"
      },
      "cell_type": "code",
      "source": [
        "def train(model, network_input, network_output):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_network()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing drive/My Drive/RapMusic/Whats_My_Name.mid\n",
            "Parsing drive/My Drive/RapMusic/U_Cant_Touch_This.mid\n",
            "Parsing drive/My Drive/RapMusic/Woo-Hah.mid\n",
            "Parsing drive/My Drive/RapMusic/Will_2K.mid\n",
            "Parsing drive/My Drive/RapMusic/Whoa.mid\n",
            "Parsing drive/My Drive/RapMusic/Wild_Wild_West.mid\n",
            "Parsing drive/My Drive/RapMusic/To_All_DJs.mid\n",
            "Parsing drive/My Drive/RapMusic/Too_Hot.mid\n",
            "Parsing drive/My Drive/RapMusic/The_Way_I_Am.mid\n",
            "Parsing drive/My Drive/RapMusic/Under_The_Influence.mid\n",
            "Parsing drive/My Drive/RapMusic/Sabotage.mid\n",
            "Parsing drive/My Drive/RapMusic/Ruff_Ryders_Anthem.mid\n",
            "Parsing drive/My Drive/RapMusic/Still_Dre.mid\n",
            "Parsing drive/My Drive/RapMusic/The_Shiznit.mid\n",
            "Parsing drive/My Drive/RapMusic/Summer_Time.mid\n",
            "Parsing drive/My Drive/RapMusic/The_Real_Slim_Shady.mid\n",
            "Parsing drive/My Drive/RapMusic/Sunshine.mid\n",
            "Parsing drive/My Drive/RapMusic/Stan.mid\n",
            "Parsing drive/My Drive/RapMusic/Still_Dont_Give_A_F_ck.mid\n",
            "Parsing drive/My Drive/RapMusic/Role_Model.mid\n",
            "Parsing drive/My Drive/RapMusic/Nothing_To_Lose.mid\n",
            "Parsing drive/My Drive/RapMusic/Notorious_Thugs.mid\n",
            "Parsing drive/My Drive/RapMusic/Rappers_Delight.mid\n",
            "Parsing drive/My Drive/RapMusic/Rock_Superstar.mid\n",
            "Parsing drive/My Drive/RapMusic/Put_Your_Hands_Where_My.mid\n",
            "Parsing drive/My Drive/RapMusic/Party_Up.mid\n",
            "Parsing drive/My Drive/RapMusic/One_More_Chance.mid\n",
            "Parsing drive/My Drive/RapMusic/Ready_To_Die.mid\n",
            "Parsing drive/My Drive/RapMusic/Not_Tonight.mid\n",
            "Parsing drive/My Drive/RapMusic/Regulate.mid\n",
            "Parsing drive/My Drive/RapMusic/Look_Into_My_Eyes.mid\n",
            "Parsing drive/My Drive/RapMusic/My_Name_Is.mid\n",
            "Parsing drive/My Drive/RapMusic/Kim.mid\n",
            "Parsing drive/My Drive/RapMusic/Mo_Money_Mo_Problems.mid\n",
            "Parsing drive/My Drive/RapMusic/Murder_Was_The_Case.mid\n",
            "Parsing drive/My Drive/RapMusic/Keep_Their_Heads_Ringing.mid\n",
            "Parsing drive/My Drive/RapMusic/Miss_U.mid\n",
            "Parsing drive/My Drive/RapMusic/Just_The_Two_Of_Us.mid\n",
            "Parsing drive/My Drive/RapMusic/Miami.mid\n",
            "Parsing drive/My Drive/RapMusic/Men_In_Black.mid\n",
            "Parsing drive/My Drive/RapMusic/Intergalactic.mid\n",
            "Parsing drive/My Drive/RapMusic/I_Am_Not_A_Player.mid\n",
            "Parsing drive/My Drive/RapMusic/Its_All_Good.mid\n",
            "Parsing drive/My Drive/RapMusic/Jamboree.mid\n",
            "Parsing drive/My Drive/RapMusic/I_Aint_Mad_Atcha.mid\n",
            "Parsing drive/My Drive/RapMusic/I_Got_The_Hook_Up.mid\n",
            "Parsing drive/My Drive/RapMusic/Its_All_About_The_Remix.mid\n",
            "Parsing drive/My Drive/RapMusic/Its_All_About_The_Benjamins.mid\n",
            "Parsing drive/My Drive/RapMusic/Ill_Be_Missing_You.mid\n",
            "Parsing drive/My Drive/RapMusic/IICCTW.mid\n",
            "Parsing drive/My Drive/RapMusic/Gettin_Jiggy_With_It.mid\n",
            "Parsing drive/My Drive/RapMusic/Ice_Ice_Baby.mid\n",
            "Parsing drive/My Drive/RapMusic/Girls.mid\n",
            "Parsing drive/My Drive/RapMusic/Gz_Hustlerz.mid\n",
            "Parsing drive/My Drive/RapMusic/Gangstas_Paradise.mid\n",
            "Parsing drive/My Drive/RapMusic/Hey_Lover.mid\n",
            "Parsing drive/My Drive/RapMusic/Guilty_Conscience.mid\n",
            "Parsing drive/My Drive/RapMusic/Hard_Knock_Life.mid\n",
            "Parsing drive/My Drive/RapMusic/Ghetto_Vet.mid\n",
            "Parsing drive/My Drive/RapMusic/Forgot_About_Dre.mid\n",
            "Parsing drive/My Drive/RapMusic/Fight_For_Your_Right_To.mid\n",
            "Parsing drive/My Drive/RapMusic/First_Of_The_Month.mid\n",
            "Parsing drive/My Drive/RapMusic/Days_Of_Our_Livez.mid\n",
            "Parsing drive/My Drive/RapMusic/Fire_It_Up_Turn_It_Up.mid\n",
            "Parsing drive/My Drive/RapMusic/C_U_When_U_Get_There.mid\n",
            "Parsing drive/My Drive/RapMusic/Crossroads.mid\n",
            "Parsing drive/My Drive/RapMusic/Fantastic_Voyage.mid\n",
            "Parsing drive/My Drive/RapMusic/Dre_Day.mid\n",
            "Parsing drive/My Drive/RapMusic/Feelin_It.mid\n",
            "Parsing drive/My Drive/RapMusic/Country_Grammar.mid\n",
            "Parsing drive/My Drive/RapMusic/Changes.mid\n",
            "Parsing drive/My Drive/RapMusic/Can_I_Get_A.mid\n",
            "Parsing drive/My Drive/RapMusic/Come_With_Me.mid\n",
            "Parsing drive/My Drive/RapMusic/Big_Pimpin.mid\n",
            "Parsing drive/My Drive/RapMusic/Been_Around_The_World.mid\n",
            "Parsing drive/My Drive/RapMusic/California_Love.mid\n",
            "Parsing drive/My Drive/RapMusic/Big_Poppa.mid\n",
            "Parsing drive/My Drive/RapMusic/Aint_Nuthin_But_A_G_Thang.mid\n",
            "Parsing drive/My Drive/RapMusic/Bad_Meets_Evil.mid\n",
            "Parsing drive/My Drive/RapMusic/Aint_Nothing_Personal.mid\n",
            "Epoch 1/200\n",
            "2058/2058 [==============================] - 25s 12ms/step - loss: 3.5484\n",
            "Epoch 2/200\n",
            "2058/2058 [==============================] - 23s 11ms/step - loss: 3.0486\n",
            "Epoch 3/200\n",
            "2058/2058 [==============================] - 23s 11ms/step - loss: 3.0299\n",
            "Epoch 4/200\n",
            "2058/2058 [==============================] - 23s 11ms/step - loss: 3.0082\n",
            "Epoch 5/200\n",
            "2058/2058 [==============================] - 23s 11ms/step - loss: 3.0033\n",
            "Epoch 6/200\n",
            "2058/2058 [==============================] - 23s 11ms/step - loss: 2.9985\n",
            "Epoch 7/200\n",
            "2058/2058 [==============================] - 23s 11ms/step - loss: 2.9965\n",
            "Epoch 8/200\n",
            "1600/2058 [======================>.......] - ETA: 4s - loss: 3.0090"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d8f7e2a3595c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-57a62e06d373>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m#training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-d8f7e2a3595c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, network_input, network_output)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}